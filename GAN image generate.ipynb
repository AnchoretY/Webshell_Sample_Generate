{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 包\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超参数设置\n",
    "# Hyper-parameters\n",
    "latent_size = 64\n",
    "hidden_size = 256\n",
    "image_size = 784\n",
    "num_epochs = 200\n",
    "batch_size = 100\n",
    "sample_dir = 'samples'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果没有文件夹就创建一个文件夹\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.makedirs(sample_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图像处理模块：transform设置\n",
    "# Image processing：归一化（将数据规整到[-1,1],计算公式：channel=（channel-mean）/std）\n",
    "transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.5],\n",
    "                                     std=[0.5]\n",
    "                )]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载同时做transform预处理\n",
    "mnist = torchvision.datasets.MNIST(root='../../../data/minist',\n",
    "                                   train=True,\n",
    "                                   transform=transform,\n",
    "                                   download=True)\n",
    "# 数据加载器：GAN中只考虑判别模型和生成模型的对抗提高，无需设置训练集和测试集\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist,\n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建判别模型\n",
    "# Discriminator\n",
    "D = nn.Sequential(\n",
    "        nn.Linear(image_size, hidden_size), # 判别的输入时图像数据\n",
    "        nn.LeakyReLU(0.2),\n",
    "        nn.Linear(hidden_size, hidden_size),\n",
    "        nn.LeakyReLU(0.2),\n",
    "        nn.Linear(hidden_size, 1),\n",
    "        nn.Sigmoid())\n",
    "\n",
    "# 创建生成模型\n",
    "# Generator \n",
    "G = nn.Sequential(\n",
    "        nn.Linear(latent_size, hidden_size), # 生成的输入是随机数，可以自己定义\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_size, hidden_size),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_size, image_size),\n",
    "        nn.Tanh())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置损失函数和优化器\n",
    "criterion = nn.BCELoss() # 二值交叉熵 Binary cross entropy loss\n",
    "d_optimizer = torch.optim.Adam(D.parameters(), lr=0.0002)\n",
    "g_optimizer = torch.optim.Adam(G.parameters(), lr=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义两个函数\n",
    "\n",
    "def denorm(x):\n",
    "    out = (x + 1) / 2\n",
    "    return out.clamp(0, 1)\n",
    "\n",
    "# 重置梯度\n",
    "def reset_grad():\n",
    "    d_optimizer.zero_grad()\n",
    "    g_optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ../../../data/minist\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Normalize(mean=[0.5], std=[0.5])\n",
       "           )"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch [0/200], Step [200/600], d_loss: 0.0464, g_loss: 4.3383, D(x): 0.99, D(G(z)): 0.04\n",
      "Epoch [0/200], Step [400/600], d_loss: 0.0692, g_loss: 5.7292, D(x): 0.98, D(G(z)): 0.04\n",
      "Epoch [0/200], Step [600/600], d_loss: 0.0430, g_loss: 4.8351, D(x): 0.99, D(G(z)): 0.03\n",
      "1\n",
      "Epoch [1/200], Step [200/600], d_loss: 0.0694, g_loss: 5.1648, D(x): 0.98, D(G(z)): 0.04\n",
      "Epoch [1/200], Step [400/600], d_loss: 0.1799, g_loss: 3.8660, D(x): 0.94, D(G(z)): 0.05\n",
      "Epoch [1/200], Step [600/600], d_loss: 0.1576, g_loss: 3.9562, D(x): 0.99, D(G(z)): 0.13\n",
      "2\n",
      "Epoch [2/200], Step [200/600], d_loss: 0.0887, g_loss: 6.1795, D(x): 0.96, D(G(z)): 0.03\n",
      "Epoch [2/200], Step [400/600], d_loss: 0.1164, g_loss: 5.4913, D(x): 0.96, D(G(z)): 0.07\n",
      "Epoch [2/200], Step [600/600], d_loss: 1.0763, g_loss: 3.3234, D(x): 0.71, D(G(z)): 0.20\n",
      "3\n",
      "Epoch [3/200], Step [200/600], d_loss: 0.3132, g_loss: 4.4578, D(x): 0.81, D(G(z)): 0.03\n",
      "Epoch [3/200], Step [400/600], d_loss: 0.9218, g_loss: 2.7380, D(x): 0.72, D(G(z)): 0.31\n",
      "Epoch [3/200], Step [600/600], d_loss: 0.1235, g_loss: 3.6332, D(x): 0.98, D(G(z)): 0.09\n",
      "4\n",
      "Epoch [4/200], Step [200/600], d_loss: 0.5204, g_loss: 3.3411, D(x): 0.84, D(G(z)): 0.16\n",
      "Epoch [4/200], Step [400/600], d_loss: 1.3260, g_loss: 1.7157, D(x): 0.70, D(G(z)): 0.45\n",
      "Epoch [4/200], Step [600/600], d_loss: 0.4004, g_loss: 2.6860, D(x): 0.85, D(G(z)): 0.15\n",
      "5\n",
      "Epoch [5/200], Step [200/600], d_loss: 0.4345, g_loss: 3.1261, D(x): 0.87, D(G(z)): 0.18\n",
      "Epoch [5/200], Step [400/600], d_loss: 0.8323, g_loss: 1.8916, D(x): 0.83, D(G(z)): 0.35\n",
      "Epoch [5/200], Step [600/600], d_loss: 0.3571, g_loss: 2.7694, D(x): 0.84, D(G(z)): 0.07\n",
      "6\n",
      "Epoch [6/200], Step [200/600], d_loss: 0.7618, g_loss: 2.2695, D(x): 0.80, D(G(z)): 0.27\n",
      "Epoch [6/200], Step [400/600], d_loss: 0.4690, g_loss: 3.4127, D(x): 0.79, D(G(z)): 0.06\n",
      "Epoch [6/200], Step [600/600], d_loss: 0.6041, g_loss: 3.2619, D(x): 0.81, D(G(z)): 0.08\n",
      "7\n",
      "Epoch [7/200], Step [200/600], d_loss: 0.2711, g_loss: 5.4561, D(x): 0.91, D(G(z)): 0.08\n",
      "Epoch [7/200], Step [400/600], d_loss: 0.2229, g_loss: 4.7108, D(x): 0.91, D(G(z)): 0.04\n",
      "Epoch [7/200], Step [600/600], d_loss: 0.5030, g_loss: 2.3143, D(x): 0.82, D(G(z)): 0.11\n",
      "8\n",
      "Epoch [8/200], Step [200/600], d_loss: 0.2340, g_loss: 3.2401, D(x): 0.92, D(G(z)): 0.07\n",
      "Epoch [8/200], Step [400/600], d_loss: 0.1398, g_loss: 4.7932, D(x): 0.97, D(G(z)): 0.09\n",
      "Epoch [8/200], Step [600/600], d_loss: 0.3812, g_loss: 5.6398, D(x): 0.86, D(G(z)): 0.04\n",
      "9\n",
      "Epoch [9/200], Step [200/600], d_loss: 0.2293, g_loss: 3.6642, D(x): 0.94, D(G(z)): 0.10\n",
      "Epoch [9/200], Step [400/600], d_loss: 0.2812, g_loss: 3.8484, D(x): 0.95, D(G(z)): 0.15\n",
      "Epoch [9/200], Step [600/600], d_loss: 0.1987, g_loss: 2.4196, D(x): 0.96, D(G(z)): 0.09\n",
      "10\n",
      "Epoch [10/200], Step [200/600], d_loss: 0.1991, g_loss: 4.9564, D(x): 0.94, D(G(z)): 0.07\n",
      "Epoch [10/200], Step [400/600], d_loss: 0.1796, g_loss: 5.0146, D(x): 0.96, D(G(z)): 0.08\n",
      "Epoch [10/200], Step [600/600], d_loss: 0.2559, g_loss: 5.0983, D(x): 0.92, D(G(z)): 0.05\n",
      "11\n",
      "Epoch [11/200], Step [200/600], d_loss: 0.4569, g_loss: 4.3478, D(x): 0.86, D(G(z)): 0.11\n",
      "Epoch [11/200], Step [400/600], d_loss: 0.1344, g_loss: 4.1074, D(x): 0.97, D(G(z)): 0.07\n",
      "Epoch [11/200], Step [600/600], d_loss: 0.3016, g_loss: 3.7900, D(x): 0.92, D(G(z)): 0.09\n",
      "12\n",
      "Epoch [12/200], Step [200/600], d_loss: 0.1823, g_loss: 3.9374, D(x): 0.94, D(G(z)): 0.03\n",
      "Epoch [12/200], Step [400/600], d_loss: 0.1545, g_loss: 3.8553, D(x): 0.95, D(G(z)): 0.06\n",
      "Epoch [12/200], Step [600/600], d_loss: 0.1189, g_loss: 4.9762, D(x): 0.94, D(G(z)): 0.02\n",
      "13\n",
      "Epoch [13/200], Step [200/600], d_loss: 0.1628, g_loss: 6.6160, D(x): 0.96, D(G(z)): 0.08\n",
      "Epoch [13/200], Step [400/600], d_loss: 0.1975, g_loss: 11.0737, D(x): 0.97, D(G(z)): 0.08\n",
      "Epoch [13/200], Step [600/600], d_loss: 0.1905, g_loss: 7.4744, D(x): 0.90, D(G(z)): 0.01\n",
      "14\n",
      "Epoch [14/200], Step [200/600], d_loss: 0.0733, g_loss: 6.6492, D(x): 0.97, D(G(z)): 0.02\n",
      "Epoch [14/200], Step [400/600], d_loss: 0.2278, g_loss: 4.4843, D(x): 0.95, D(G(z)): 0.06\n",
      "Epoch [14/200], Step [600/600], d_loss: 0.0395, g_loss: 5.3803, D(x): 0.99, D(G(z)): 0.03\n",
      "15\n",
      "Epoch [15/200], Step [200/600], d_loss: 0.1694, g_loss: 5.8386, D(x): 0.96, D(G(z)): 0.02\n",
      "Epoch [15/200], Step [400/600], d_loss: 0.0480, g_loss: 5.5042, D(x): 0.98, D(G(z)): 0.01\n",
      "Epoch [15/200], Step [600/600], d_loss: 0.1635, g_loss: 7.4298, D(x): 0.95, D(G(z)): 0.05\n",
      "16\n",
      "Epoch [16/200], Step [200/600], d_loss: 0.0761, g_loss: 5.4621, D(x): 0.99, D(G(z)): 0.05\n",
      "Epoch [16/200], Step [400/600], d_loss: 0.2043, g_loss: 6.8362, D(x): 0.93, D(G(z)): 0.02\n",
      "Epoch [16/200], Step [600/600], d_loss: 0.1246, g_loss: 3.6152, D(x): 0.99, D(G(z)): 0.10\n",
      "17\n",
      "Epoch [17/200], Step [200/600], d_loss: 0.0753, g_loss: 5.0165, D(x): 0.97, D(G(z)): 0.02\n",
      "Epoch [17/200], Step [400/600], d_loss: 0.1698, g_loss: 5.4128, D(x): 0.94, D(G(z)): 0.01\n",
      "Epoch [17/200], Step [600/600], d_loss: 0.2862, g_loss: 6.0100, D(x): 0.92, D(G(z)): 0.06\n",
      "18\n",
      "Epoch [18/200], Step [200/600], d_loss: 0.4549, g_loss: 4.4522, D(x): 0.95, D(G(z)): 0.23\n",
      "Epoch [18/200], Step [400/600], d_loss: 0.4213, g_loss: 4.4086, D(x): 0.89, D(G(z)): 0.09\n",
      "Epoch [18/200], Step [600/600], d_loss: 0.2253, g_loss: 7.2647, D(x): 0.91, D(G(z)): 0.01\n",
      "19\n",
      "Epoch [19/200], Step [200/600], d_loss: 0.2417, g_loss: 5.2380, D(x): 0.92, D(G(z)): 0.06\n",
      "Epoch [19/200], Step [400/600], d_loss: 0.4133, g_loss: 4.3189, D(x): 0.84, D(G(z)): 0.05\n",
      "Epoch [19/200], Step [600/600], d_loss: 0.3878, g_loss: 3.9634, D(x): 0.91, D(G(z)): 0.16\n",
      "20\n",
      "Epoch [20/200], Step [200/600], d_loss: 0.8631, g_loss: 4.0460, D(x): 0.88, D(G(z)): 0.27\n",
      "Epoch [20/200], Step [400/600], d_loss: 0.2847, g_loss: 3.8243, D(x): 0.95, D(G(z)): 0.14\n",
      "Epoch [20/200], Step [600/600], d_loss: 0.4321, g_loss: 2.1721, D(x): 0.89, D(G(z)): 0.15\n",
      "21\n",
      "Epoch [21/200], Step [200/600], d_loss: 0.3093, g_loss: 4.1704, D(x): 0.90, D(G(z)): 0.06\n",
      "Epoch [21/200], Step [400/600], d_loss: 0.2157, g_loss: 3.9601, D(x): 0.91, D(G(z)): 0.06\n",
      "Epoch [21/200], Step [600/600], d_loss: 0.3578, g_loss: 4.4039, D(x): 0.91, D(G(z)): 0.10\n",
      "22\n",
      "Epoch [22/200], Step [200/600], d_loss: 0.1920, g_loss: 4.8568, D(x): 0.96, D(G(z)): 0.06\n",
      "Epoch [22/200], Step [400/600], d_loss: 0.2666, g_loss: 3.5426, D(x): 0.89, D(G(z)): 0.04\n",
      "Epoch [22/200], Step [600/600], d_loss: 0.0970, g_loss: 3.9732, D(x): 0.98, D(G(z)): 0.05\n",
      "23\n",
      "Epoch [23/200], Step [200/600], d_loss: 0.1935, g_loss: 3.7038, D(x): 0.92, D(G(z)): 0.05\n",
      "Epoch [23/200], Step [400/600], d_loss: 0.3616, g_loss: 4.3868, D(x): 0.90, D(G(z)): 0.12\n",
      "Epoch [23/200], Step [600/600], d_loss: 0.4345, g_loss: 3.8124, D(x): 0.85, D(G(z)): 0.04\n",
      "24\n",
      "Epoch [24/200], Step [200/600], d_loss: 0.2967, g_loss: 4.4424, D(x): 0.96, D(G(z)): 0.11\n",
      "Epoch [24/200], Step [400/600], d_loss: 0.3549, g_loss: 3.6729, D(x): 0.94, D(G(z)): 0.17\n",
      "Epoch [24/200], Step [600/600], d_loss: 0.3440, g_loss: 5.7896, D(x): 0.87, D(G(z)): 0.02\n",
      "25\n",
      "Epoch [25/200], Step [200/600], d_loss: 0.3454, g_loss: 3.2100, D(x): 0.93, D(G(z)): 0.16\n",
      "Epoch [25/200], Step [400/600], d_loss: 0.3234, g_loss: 2.7425, D(x): 0.90, D(G(z)): 0.12\n",
      "Epoch [25/200], Step [600/600], d_loss: 0.2827, g_loss: 5.0025, D(x): 0.89, D(G(z)): 0.06\n",
      "26\n",
      "Epoch [26/200], Step [200/600], d_loss: 0.3515, g_loss: 3.2090, D(x): 0.91, D(G(z)): 0.08\n",
      "Epoch [26/200], Step [400/600], d_loss: 0.3519, g_loss: 4.9732, D(x): 0.87, D(G(z)): 0.08\n",
      "Epoch [26/200], Step [600/600], d_loss: 0.3125, g_loss: 3.7734, D(x): 0.89, D(G(z)): 0.10\n",
      "27\n",
      "Epoch [27/200], Step [200/600], d_loss: 0.2965, g_loss: 2.5239, D(x): 0.90, D(G(z)): 0.10\n",
      "Epoch [27/200], Step [400/600], d_loss: 0.3375, g_loss: 3.4252, D(x): 0.92, D(G(z)): 0.14\n",
      "Epoch [27/200], Step [600/600], d_loss: 0.2850, g_loss: 3.4592, D(x): 0.94, D(G(z)): 0.13\n",
      "28\n",
      "Epoch [28/200], Step [200/600], d_loss: 0.3113, g_loss: 2.9944, D(x): 0.88, D(G(z)): 0.07\n",
      "Epoch [28/200], Step [400/600], d_loss: 0.3209, g_loss: 3.0054, D(x): 0.94, D(G(z)): 0.16\n",
      "Epoch [28/200], Step [600/600], d_loss: 0.3633, g_loss: 2.7669, D(x): 0.91, D(G(z)): 0.16\n",
      "29\n",
      "Epoch [29/200], Step [200/600], d_loss: 0.5652, g_loss: 4.0396, D(x): 0.80, D(G(z)): 0.04\n",
      "Epoch [29/200], Step [400/600], d_loss: 0.3772, g_loss: 3.8361, D(x): 0.89, D(G(z)): 0.08\n",
      "Epoch [29/200], Step [600/600], d_loss: 0.2326, g_loss: 3.5978, D(x): 0.93, D(G(z)): 0.10\n",
      "30\n",
      "Epoch [30/200], Step [200/600], d_loss: 0.3415, g_loss: 3.8294, D(x): 0.92, D(G(z)): 0.14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/200], Step [400/600], d_loss: 0.4801, g_loss: 2.4151, D(x): 0.94, D(G(z)): 0.19\n",
      "Epoch [30/200], Step [600/600], d_loss: 0.3523, g_loss: 2.8145, D(x): 0.91, D(G(z)): 0.08\n",
      "31\n",
      "Epoch [31/200], Step [200/600], d_loss: 0.2225, g_loss: 3.5557, D(x): 0.94, D(G(z)): 0.10\n",
      "Epoch [31/200], Step [400/600], d_loss: 0.3795, g_loss: 4.0062, D(x): 0.92, D(G(z)): 0.15\n",
      "Epoch [31/200], Step [600/600], d_loss: 0.3349, g_loss: 3.3495, D(x): 0.92, D(G(z)): 0.16\n",
      "32\n",
      "Epoch [32/200], Step [200/600], d_loss: 0.4207, g_loss: 3.0028, D(x): 0.85, D(G(z)): 0.07\n",
      "Epoch [32/200], Step [400/600], d_loss: 0.4044, g_loss: 3.8022, D(x): 0.89, D(G(z)): 0.13\n",
      "Epoch [32/200], Step [600/600], d_loss: 0.3144, g_loss: 3.9625, D(x): 0.94, D(G(z)): 0.16\n",
      "33\n",
      "Epoch [33/200], Step [200/600], d_loss: 0.5007, g_loss: 2.9901, D(x): 0.97, D(G(z)): 0.30\n",
      "Epoch [33/200], Step [400/600], d_loss: 0.3633, g_loss: 3.5251, D(x): 0.91, D(G(z)): 0.13\n",
      "Epoch [33/200], Step [600/600], d_loss: 0.3709, g_loss: 2.8944, D(x): 0.86, D(G(z)): 0.09\n",
      "34\n",
      "Epoch [34/200], Step [200/600], d_loss: 0.4386, g_loss: 2.2569, D(x): 0.84, D(G(z)): 0.10\n",
      "Epoch [34/200], Step [400/600], d_loss: 0.3701, g_loss: 4.1251, D(x): 0.88, D(G(z)): 0.12\n",
      "Epoch [34/200], Step [600/600], d_loss: 0.4704, g_loss: 3.5835, D(x): 0.89, D(G(z)): 0.20\n",
      "35\n",
      "Epoch [35/200], Step [200/600], d_loss: 0.3676, g_loss: 3.4377, D(x): 0.88, D(G(z)): 0.11\n",
      "Epoch [35/200], Step [400/600], d_loss: 0.4861, g_loss: 2.4048, D(x): 0.87, D(G(z)): 0.20\n",
      "Epoch [35/200], Step [600/600], d_loss: 0.4704, g_loss: 2.1033, D(x): 0.84, D(G(z)): 0.17\n",
      "36\n",
      "Epoch [36/200], Step [200/600], d_loss: 0.4125, g_loss: 2.9245, D(x): 0.86, D(G(z)): 0.15\n",
      "Epoch [36/200], Step [400/600], d_loss: 0.4351, g_loss: 2.4562, D(x): 0.90, D(G(z)): 0.20\n",
      "Epoch [36/200], Step [600/600], d_loss: 0.4417, g_loss: 3.9165, D(x): 0.82, D(G(z)): 0.10\n",
      "37\n",
      "Epoch [37/200], Step [200/600], d_loss: 0.5990, g_loss: 3.2328, D(x): 0.78, D(G(z)): 0.11\n",
      "Epoch [37/200], Step [400/600], d_loss: 0.3599, g_loss: 2.8833, D(x): 0.91, D(G(z)): 0.16\n",
      "Epoch [37/200], Step [600/600], d_loss: 0.3963, g_loss: 3.0612, D(x): 0.84, D(G(z)): 0.08\n",
      "38\n",
      "Epoch [38/200], Step [200/600], d_loss: 0.4925, g_loss: 2.9546, D(x): 0.83, D(G(z)): 0.11\n",
      "Epoch [38/200], Step [400/600], d_loss: 0.4415, g_loss: 3.4938, D(x): 0.86, D(G(z)): 0.14\n",
      "Epoch [38/200], Step [600/600], d_loss: 0.6508, g_loss: 2.9958, D(x): 0.86, D(G(z)): 0.22\n",
      "39\n",
      "Epoch [39/200], Step [200/600], d_loss: 0.4949, g_loss: 2.8093, D(x): 0.84, D(G(z)): 0.15\n",
      "Epoch [39/200], Step [400/600], d_loss: 0.7018, g_loss: 3.5618, D(x): 0.73, D(G(z)): 0.07\n",
      "Epoch [39/200], Step [600/600], d_loss: 0.3281, g_loss: 4.6077, D(x): 0.88, D(G(z)): 0.05\n",
      "40\n",
      "Epoch [40/200], Step [200/600], d_loss: 0.4247, g_loss: 4.2876, D(x): 0.92, D(G(z)): 0.15\n",
      "Epoch [40/200], Step [400/600], d_loss: 0.3275, g_loss: 2.5961, D(x): 0.91, D(G(z)): 0.13\n",
      "Epoch [40/200], Step [600/600], d_loss: 0.3109, g_loss: 4.2447, D(x): 0.91, D(G(z)): 0.11\n",
      "41\n",
      "Epoch [41/200], Step [200/600], d_loss: 0.4249, g_loss: 2.9264, D(x): 0.87, D(G(z)): 0.15\n",
      "Epoch [41/200], Step [400/600], d_loss: 0.5123, g_loss: 2.5764, D(x): 0.85, D(G(z)): 0.14\n",
      "Epoch [41/200], Step [600/600], d_loss: 0.4041, g_loss: 3.1148, D(x): 0.91, D(G(z)): 0.19\n",
      "42\n",
      "Epoch [42/200], Step [200/600], d_loss: 0.3925, g_loss: 3.3182, D(x): 0.89, D(G(z)): 0.13\n",
      "Epoch [42/200], Step [400/600], d_loss: 0.6681, g_loss: 3.5288, D(x): 0.78, D(G(z)): 0.10\n",
      "Epoch [42/200], Step [600/600], d_loss: 0.7619, g_loss: 2.4765, D(x): 0.74, D(G(z)): 0.14\n",
      "43\n",
      "Epoch [43/200], Step [200/600], d_loss: 0.5643, g_loss: 2.0086, D(x): 0.88, D(G(z)): 0.23\n",
      "Epoch [43/200], Step [400/600], d_loss: 0.4966, g_loss: 2.8418, D(x): 0.88, D(G(z)): 0.19\n",
      "Epoch [43/200], Step [600/600], d_loss: 0.6368, g_loss: 3.0720, D(x): 0.76, D(G(z)): 0.09\n",
      "44\n",
      "Epoch [44/200], Step [200/600], d_loss: 0.5728, g_loss: 2.2830, D(x): 0.84, D(G(z)): 0.23\n",
      "Epoch [44/200], Step [400/600], d_loss: 0.5039, g_loss: 2.3927, D(x): 0.81, D(G(z)): 0.15\n",
      "Epoch [44/200], Step [600/600], d_loss: 0.4615, g_loss: 2.8364, D(x): 0.82, D(G(z)): 0.14\n",
      "45\n",
      "Epoch [45/200], Step [200/600], d_loss: 0.5818, g_loss: 2.6011, D(x): 0.80, D(G(z)): 0.15\n",
      "Epoch [45/200], Step [400/600], d_loss: 0.4277, g_loss: 2.8229, D(x): 0.89, D(G(z)): 0.18\n",
      "Epoch [45/200], Step [600/600], d_loss: 0.4246, g_loss: 3.4678, D(x): 0.88, D(G(z)): 0.16\n",
      "46\n",
      "Epoch [46/200], Step [200/600], d_loss: 0.7394, g_loss: 2.1769, D(x): 0.71, D(G(z)): 0.09\n",
      "Epoch [46/200], Step [400/600], d_loss: 0.7006, g_loss: 2.6131, D(x): 0.82, D(G(z)): 0.24\n",
      "Epoch [46/200], Step [600/600], d_loss: 0.5945, g_loss: 2.3808, D(x): 0.83, D(G(z)): 0.19\n",
      "47\n",
      "Epoch [47/200], Step [200/600], d_loss: 0.8126, g_loss: 2.7109, D(x): 0.69, D(G(z)): 0.10\n",
      "Epoch [47/200], Step [400/600], d_loss: 0.5407, g_loss: 3.0375, D(x): 0.83, D(G(z)): 0.18\n",
      "Epoch [47/200], Step [600/600], d_loss: 0.4881, g_loss: 3.0882, D(x): 0.90, D(G(z)): 0.22\n",
      "48\n",
      "Epoch [48/200], Step [200/600], d_loss: 0.5671, g_loss: 2.1644, D(x): 0.86, D(G(z)): 0.22\n",
      "Epoch [48/200], Step [400/600], d_loss: 0.5512, g_loss: 2.2591, D(x): 0.91, D(G(z)): 0.29\n",
      "Epoch [48/200], Step [600/600], d_loss: 0.6128, g_loss: 2.1851, D(x): 0.79, D(G(z)): 0.15\n",
      "49\n",
      "Epoch [49/200], Step [200/600], d_loss: 0.4997, g_loss: 3.9474, D(x): 0.86, D(G(z)): 0.21\n",
      "Epoch [49/200], Step [400/600], d_loss: 0.5963, g_loss: 2.4501, D(x): 0.81, D(G(z)): 0.16\n",
      "Epoch [49/200], Step [600/600], d_loss: 0.5318, g_loss: 2.3278, D(x): 0.90, D(G(z)): 0.23\n",
      "50\n",
      "Epoch [50/200], Step [200/600], d_loss: 0.6405, g_loss: 2.2995, D(x): 0.84, D(G(z)): 0.24\n",
      "Epoch [50/200], Step [400/600], d_loss: 0.6961, g_loss: 2.5932, D(x): 0.75, D(G(z)): 0.15\n",
      "Epoch [50/200], Step [600/600], d_loss: 0.4121, g_loss: 3.5492, D(x): 0.89, D(G(z)): 0.16\n",
      "51\n",
      "Epoch [51/200], Step [200/600], d_loss: 0.3374, g_loss: 3.9003, D(x): 0.89, D(G(z)): 0.10\n",
      "Epoch [51/200], Step [400/600], d_loss: 0.4326, g_loss: 2.9532, D(x): 0.89, D(G(z)): 0.17\n",
      "Epoch [51/200], Step [600/600], d_loss: 0.5102, g_loss: 2.9239, D(x): 0.90, D(G(z)): 0.24\n",
      "52\n",
      "Epoch [52/200], Step [200/600], d_loss: 0.4154, g_loss: 4.0989, D(x): 0.85, D(G(z)): 0.12\n",
      "Epoch [52/200], Step [400/600], d_loss: 0.4206, g_loss: 2.5677, D(x): 0.84, D(G(z)): 0.12\n",
      "Epoch [52/200], Step [600/600], d_loss: 0.4766, g_loss: 2.8652, D(x): 0.85, D(G(z)): 0.17\n",
      "53\n",
      "Epoch [53/200], Step [200/600], d_loss: 0.5263, g_loss: 3.2691, D(x): 0.80, D(G(z)): 0.13\n",
      "Epoch [53/200], Step [400/600], d_loss: 0.6160, g_loss: 2.6476, D(x): 0.75, D(G(z)): 0.13\n",
      "Epoch [53/200], Step [600/600], d_loss: 0.6970, g_loss: 2.6519, D(x): 0.87, D(G(z)): 0.30\n",
      "54\n",
      "Epoch [54/200], Step [200/600], d_loss: 0.4515, g_loss: 2.4077, D(x): 0.82, D(G(z)): 0.14\n",
      "Epoch [54/200], Step [400/600], d_loss: 0.4923, g_loss: 2.4318, D(x): 0.86, D(G(z)): 0.18\n",
      "Epoch [54/200], Step [600/600], d_loss: 0.7161, g_loss: 1.3386, D(x): 0.82, D(G(z)): 0.26\n",
      "55\n",
      "Epoch [55/200], Step [200/600], d_loss: 0.6367, g_loss: 2.4110, D(x): 0.82, D(G(z)): 0.24\n",
      "Epoch [55/200], Step [400/600], d_loss: 0.6945, g_loss: 1.9513, D(x): 0.81, D(G(z)): 0.27\n",
      "Epoch [55/200], Step [600/600], d_loss: 0.8751, g_loss: 2.3937, D(x): 0.71, D(G(z)): 0.18\n",
      "56\n",
      "Epoch [56/200], Step [200/600], d_loss: 0.4833, g_loss: 2.4633, D(x): 0.84, D(G(z)): 0.19\n",
      "Epoch [56/200], Step [400/600], d_loss: 0.6765, g_loss: 2.2186, D(x): 0.78, D(G(z)): 0.20\n",
      "Epoch [56/200], Step [600/600], d_loss: 0.6570, g_loss: 2.7109, D(x): 0.76, D(G(z)): 0.18\n",
      "57\n",
      "Epoch [57/200], Step [200/600], d_loss: 0.5830, g_loss: 2.1741, D(x): 0.84, D(G(z)): 0.23\n",
      "Epoch [57/200], Step [400/600], d_loss: 0.6222, g_loss: 1.9894, D(x): 0.82, D(G(z)): 0.25\n",
      "Epoch [57/200], Step [600/600], d_loss: 0.6383, g_loss: 1.9117, D(x): 0.83, D(G(z)): 0.25\n",
      "58\n",
      "Epoch [58/200], Step [200/600], d_loss: 0.6230, g_loss: 3.0985, D(x): 0.89, D(G(z)): 0.30\n",
      "Epoch [58/200], Step [400/600], d_loss: 0.7179, g_loss: 2.6164, D(x): 0.80, D(G(z)): 0.22\n",
      "Epoch [58/200], Step [600/600], d_loss: 0.8483, g_loss: 2.2043, D(x): 0.78, D(G(z)): 0.30\n",
      "59\n",
      "Epoch [59/200], Step [200/600], d_loss: 0.7153, g_loss: 2.2441, D(x): 0.84, D(G(z)): 0.30\n",
      "Epoch [59/200], Step [400/600], d_loss: 0.4477, g_loss: 2.3349, D(x): 0.83, D(G(z)): 0.15\n",
      "Epoch [59/200], Step [600/600], d_loss: 0.8510, g_loss: 1.6309, D(x): 0.73, D(G(z)): 0.24\n",
      "60\n",
      "Epoch [60/200], Step [200/600], d_loss: 0.7464, g_loss: 2.2439, D(x): 0.70, D(G(z)): 0.15\n",
      "Epoch [60/200], Step [400/600], d_loss: 0.4299, g_loss: 2.5831, D(x): 0.88, D(G(z)): 0.19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/200], Step [600/600], d_loss: 0.4094, g_loss: 2.8184, D(x): 0.84, D(G(z)): 0.13\n",
      "61\n",
      "Epoch [61/200], Step [200/600], d_loss: 0.6034, g_loss: 1.7888, D(x): 0.84, D(G(z)): 0.25\n",
      "Epoch [61/200], Step [400/600], d_loss: 0.8144, g_loss: 1.6790, D(x): 0.90, D(G(z)): 0.40\n",
      "Epoch [61/200], Step [600/600], d_loss: 0.6699, g_loss: 2.5744, D(x): 0.78, D(G(z)): 0.18\n",
      "62\n",
      "Epoch [62/200], Step [200/600], d_loss: 0.6187, g_loss: 2.0890, D(x): 0.80, D(G(z)): 0.22\n",
      "Epoch [62/200], Step [400/600], d_loss: 0.4041, g_loss: 2.7356, D(x): 0.85, D(G(z)): 0.13\n",
      "Epoch [62/200], Step [600/600], d_loss: 0.6275, g_loss: 2.5331, D(x): 0.88, D(G(z)): 0.30\n",
      "63\n",
      "Epoch [63/200], Step [200/600], d_loss: 0.7378, g_loss: 2.0894, D(x): 0.73, D(G(z)): 0.15\n",
      "Epoch [63/200], Step [400/600], d_loss: 0.5141, g_loss: 2.4319, D(x): 0.79, D(G(z)): 0.14\n",
      "Epoch [63/200], Step [600/600], d_loss: 0.5284, g_loss: 3.6558, D(x): 0.86, D(G(z)): 0.20\n",
      "64\n",
      "Epoch [64/200], Step [200/600], d_loss: 0.4568, g_loss: 3.1004, D(x): 0.85, D(G(z)): 0.16\n",
      "Epoch [64/200], Step [400/600], d_loss: 0.7518, g_loss: 1.8934, D(x): 0.73, D(G(z)): 0.18\n",
      "Epoch [64/200], Step [600/600], d_loss: 0.7694, g_loss: 2.0845, D(x): 0.78, D(G(z)): 0.28\n",
      "65\n",
      "Epoch [65/200], Step [200/600], d_loss: 0.6701, g_loss: 2.6824, D(x): 0.79, D(G(z)): 0.19\n",
      "Epoch [65/200], Step [400/600], d_loss: 0.6650, g_loss: 2.3230, D(x): 0.85, D(G(z)): 0.31\n",
      "Epoch [65/200], Step [600/600], d_loss: 0.5156, g_loss: 2.5279, D(x): 0.88, D(G(z)): 0.25\n",
      "66\n",
      "Epoch [66/200], Step [200/600], d_loss: 0.5996, g_loss: 2.9729, D(x): 0.78, D(G(z)): 0.17\n",
      "Epoch [66/200], Step [400/600], d_loss: 0.4926, g_loss: 1.8449, D(x): 0.86, D(G(z)): 0.20\n",
      "Epoch [66/200], Step [600/600], d_loss: 0.8680, g_loss: 2.2714, D(x): 0.79, D(G(z)): 0.33\n",
      "67\n",
      "Epoch [67/200], Step [200/600], d_loss: 0.7962, g_loss: 2.0268, D(x): 0.82, D(G(z)): 0.35\n",
      "Epoch [67/200], Step [400/600], d_loss: 0.6187, g_loss: 2.2740, D(x): 0.74, D(G(z)): 0.16\n",
      "Epoch [67/200], Step [600/600], d_loss: 0.7231, g_loss: 2.3610, D(x): 0.83, D(G(z)): 0.29\n",
      "68\n",
      "Epoch [68/200], Step [200/600], d_loss: 0.8661, g_loss: 1.6180, D(x): 0.79, D(G(z)): 0.32\n",
      "Epoch [68/200], Step [400/600], d_loss: 0.6194, g_loss: 2.8438, D(x): 0.80, D(G(z)): 0.22\n",
      "Epoch [68/200], Step [600/600], d_loss: 0.5750, g_loss: 2.3001, D(x): 0.81, D(G(z)): 0.22\n",
      "69\n",
      "Epoch [69/200], Step [200/600], d_loss: 0.6437, g_loss: 2.2906, D(x): 0.84, D(G(z)): 0.26\n",
      "Epoch [69/200], Step [400/600], d_loss: 0.6777, g_loss: 1.7757, D(x): 0.77, D(G(z)): 0.22\n",
      "Epoch [69/200], Step [600/600], d_loss: 0.7003, g_loss: 2.0795, D(x): 0.74, D(G(z)): 0.17\n",
      "70\n",
      "Epoch [70/200], Step [200/600], d_loss: 0.7319, g_loss: 2.4972, D(x): 0.73, D(G(z)): 0.19\n",
      "Epoch [70/200], Step [400/600], d_loss: 0.7023, g_loss: 1.4390, D(x): 0.79, D(G(z)): 0.29\n",
      "Epoch [70/200], Step [600/600], d_loss: 0.5890, g_loss: 2.2650, D(x): 0.80, D(G(z)): 0.22\n",
      "71\n",
      "Epoch [71/200], Step [200/600], d_loss: 0.6440, g_loss: 1.7388, D(x): 0.78, D(G(z)): 0.22\n",
      "Epoch [71/200], Step [400/600], d_loss: 0.7478, g_loss: 1.8212, D(x): 0.81, D(G(z)): 0.29\n",
      "Epoch [71/200], Step [600/600], d_loss: 0.6285, g_loss: 1.7664, D(x): 0.80, D(G(z)): 0.22\n",
      "72\n",
      "Epoch [72/200], Step [200/600], d_loss: 0.7681, g_loss: 1.9874, D(x): 0.72, D(G(z)): 0.21\n",
      "Epoch [72/200], Step [400/600], d_loss: 0.8084, g_loss: 2.3715, D(x): 0.70, D(G(z)): 0.21\n",
      "Epoch [72/200], Step [600/600], d_loss: 0.7335, g_loss: 2.3080, D(x): 0.76, D(G(z)): 0.20\n",
      "73\n",
      "Epoch [73/200], Step [200/600], d_loss: 0.8534, g_loss: 1.5026, D(x): 0.77, D(G(z)): 0.31\n",
      "Epoch [73/200], Step [400/600], d_loss: 0.9151, g_loss: 2.5081, D(x): 0.77, D(G(z)): 0.29\n",
      "Epoch [73/200], Step [600/600], d_loss: 0.6563, g_loss: 2.4739, D(x): 0.75, D(G(z)): 0.19\n",
      "74\n",
      "Epoch [74/200], Step [200/600], d_loss: 0.9043, g_loss: 2.2603, D(x): 0.71, D(G(z)): 0.22\n",
      "Epoch [74/200], Step [400/600], d_loss: 0.8430, g_loss: 1.9485, D(x): 0.76, D(G(z)): 0.26\n",
      "Epoch [74/200], Step [600/600], d_loss: 0.7482, g_loss: 2.1278, D(x): 0.73, D(G(z)): 0.20\n",
      "75\n",
      "Epoch [75/200], Step [200/600], d_loss: 0.7888, g_loss: 2.4165, D(x): 0.71, D(G(z)): 0.19\n",
      "Epoch [75/200], Step [400/600], d_loss: 0.6712, g_loss: 1.8847, D(x): 0.81, D(G(z)): 0.23\n",
      "Epoch [75/200], Step [600/600], d_loss: 0.7839, g_loss: 2.2180, D(x): 0.81, D(G(z)): 0.31\n",
      "76\n",
      "Epoch [76/200], Step [200/600], d_loss: 0.7501, g_loss: 1.9467, D(x): 0.72, D(G(z)): 0.17\n",
      "Epoch [76/200], Step [400/600], d_loss: 0.8972, g_loss: 2.7697, D(x): 0.75, D(G(z)): 0.30\n",
      "Epoch [76/200], Step [600/600], d_loss: 0.8191, g_loss: 1.7165, D(x): 0.80, D(G(z)): 0.33\n",
      "77\n",
      "Epoch [77/200], Step [200/600], d_loss: 0.7979, g_loss: 1.8323, D(x): 0.79, D(G(z)): 0.31\n",
      "Epoch [77/200], Step [400/600], d_loss: 0.9068, g_loss: 2.0263, D(x): 0.69, D(G(z)): 0.24\n",
      "Epoch [77/200], Step [600/600], d_loss: 0.7004, g_loss: 2.2386, D(x): 0.85, D(G(z)): 0.28\n",
      "78\n",
      "Epoch [78/200], Step [200/600], d_loss: 0.7130, g_loss: 2.1715, D(x): 0.76, D(G(z)): 0.18\n",
      "Epoch [78/200], Step [400/600], d_loss: 0.7371, g_loss: 2.4598, D(x): 0.75, D(G(z)): 0.23\n",
      "Epoch [78/200], Step [600/600], d_loss: 0.6213, g_loss: 2.3967, D(x): 0.82, D(G(z)): 0.24\n",
      "79\n",
      "Epoch [79/200], Step [200/600], d_loss: 0.6864, g_loss: 2.5739, D(x): 0.75, D(G(z)): 0.20\n",
      "Epoch [79/200], Step [400/600], d_loss: 0.6065, g_loss: 1.6958, D(x): 0.78, D(G(z)): 0.21\n",
      "Epoch [79/200], Step [600/600], d_loss: 0.8329, g_loss: 2.4162, D(x): 0.66, D(G(z)): 0.15\n",
      "80\n",
      "Epoch [80/200], Step [200/600], d_loss: 0.9830, g_loss: 2.3670, D(x): 0.68, D(G(z)): 0.25\n",
      "Epoch [80/200], Step [400/600], d_loss: 0.8676, g_loss: 2.6779, D(x): 0.76, D(G(z)): 0.24\n",
      "Epoch [80/200], Step [600/600], d_loss: 0.6148, g_loss: 2.7598, D(x): 0.79, D(G(z)): 0.20\n",
      "81\n",
      "Epoch [81/200], Step [200/600], d_loss: 0.8170, g_loss: 1.9569, D(x): 0.73, D(G(z)): 0.26\n",
      "Epoch [81/200], Step [400/600], d_loss: 0.6896, g_loss: 1.8661, D(x): 0.76, D(G(z)): 0.24\n",
      "Epoch [81/200], Step [600/600], d_loss: 0.5825, g_loss: 2.8345, D(x): 0.74, D(G(z)): 0.10\n",
      "82\n",
      "Epoch [82/200], Step [200/600], d_loss: 0.8985, g_loss: 1.8595, D(x): 0.71, D(G(z)): 0.28\n",
      "Epoch [82/200], Step [400/600], d_loss: 0.8150, g_loss: 1.8121, D(x): 0.73, D(G(z)): 0.23\n",
      "Epoch [82/200], Step [600/600], d_loss: 0.5895, g_loss: 2.1480, D(x): 0.75, D(G(z)): 0.14\n",
      "83\n",
      "Epoch [83/200], Step [200/600], d_loss: 0.8795, g_loss: 1.2870, D(x): 0.73, D(G(z)): 0.30\n",
      "Epoch [83/200], Step [400/600], d_loss: 0.9006, g_loss: 1.5513, D(x): 0.79, D(G(z)): 0.36\n",
      "Epoch [83/200], Step [600/600], d_loss: 0.6149, g_loss: 1.5524, D(x): 0.80, D(G(z)): 0.24\n",
      "84\n",
      "Epoch [84/200], Step [200/600], d_loss: 0.7752, g_loss: 1.9406, D(x): 0.69, D(G(z)): 0.17\n",
      "Epoch [84/200], Step [400/600], d_loss: 0.8800, g_loss: 1.5562, D(x): 0.68, D(G(z)): 0.21\n",
      "Epoch [84/200], Step [600/600], d_loss: 0.8971, g_loss: 2.5741, D(x): 0.77, D(G(z)): 0.31\n",
      "85\n",
      "Epoch [85/200], Step [200/600], d_loss: 0.6427, g_loss: 2.0763, D(x): 0.79, D(G(z)): 0.22\n",
      "Epoch [85/200], Step [400/600], d_loss: 0.6373, g_loss: 2.2147, D(x): 0.79, D(G(z)): 0.23\n",
      "Epoch [85/200], Step [600/600], d_loss: 0.7764, g_loss: 1.8986, D(x): 0.79, D(G(z)): 0.27\n",
      "86\n",
      "Epoch [86/200], Step [200/600], d_loss: 0.6119, g_loss: 2.3756, D(x): 0.79, D(G(z)): 0.21\n",
      "Epoch [86/200], Step [400/600], d_loss: 0.6620, g_loss: 2.0466, D(x): 0.75, D(G(z)): 0.19\n",
      "Epoch [86/200], Step [600/600], d_loss: 0.8104, g_loss: 1.9243, D(x): 0.74, D(G(z)): 0.29\n",
      "87\n",
      "Epoch [87/200], Step [200/600], d_loss: 0.8713, g_loss: 2.3904, D(x): 0.67, D(G(z)): 0.23\n",
      "Epoch [87/200], Step [400/600], d_loss: 0.7704, g_loss: 1.7617, D(x): 0.77, D(G(z)): 0.28\n",
      "Epoch [87/200], Step [600/600], d_loss: 0.6635, g_loss: 2.2666, D(x): 0.74, D(G(z)): 0.17\n",
      "88\n",
      "Epoch [88/200], Step [200/600], d_loss: 0.7683, g_loss: 1.9731, D(x): 0.77, D(G(z)): 0.28\n",
      "Epoch [88/200], Step [400/600], d_loss: 0.6009, g_loss: 2.7984, D(x): 0.75, D(G(z)): 0.15\n",
      "Epoch [88/200], Step [600/600], d_loss: 0.7549, g_loss: 2.3141, D(x): 0.75, D(G(z)): 0.24\n",
      "89\n",
      "Epoch [89/200], Step [200/600], d_loss: 0.8954, g_loss: 1.4237, D(x): 0.75, D(G(z)): 0.33\n",
      "Epoch [89/200], Step [400/600], d_loss: 0.5855, g_loss: 2.8668, D(x): 0.80, D(G(z)): 0.19\n",
      "Epoch [89/200], Step [600/600], d_loss: 0.7915, g_loss: 1.8013, D(x): 0.72, D(G(z)): 0.25\n",
      "90\n",
      "Epoch [90/200], Step [200/600], d_loss: 0.5673, g_loss: 2.9363, D(x): 0.75, D(G(z)): 0.15\n",
      "Epoch [90/200], Step [400/600], d_loss: 0.5403, g_loss: 2.4721, D(x): 0.81, D(G(z)): 0.21\n",
      "Epoch [90/200], Step [600/600], d_loss: 0.8246, g_loss: 2.0482, D(x): 0.78, D(G(z)): 0.28\n",
      "91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [91/200], Step [200/600], d_loss: 0.8491, g_loss: 2.2690, D(x): 0.73, D(G(z)): 0.27\n",
      "Epoch [91/200], Step [400/600], d_loss: 0.8051, g_loss: 1.9026, D(x): 0.79, D(G(z)): 0.32\n",
      "Epoch [91/200], Step [600/600], d_loss: 0.8104, g_loss: 2.0632, D(x): 0.70, D(G(z)): 0.22\n",
      "92\n",
      "Epoch [92/200], Step [200/600], d_loss: 0.7204, g_loss: 1.7888, D(x): 0.79, D(G(z)): 0.29\n",
      "Epoch [92/200], Step [400/600], d_loss: 0.8677, g_loss: 1.6029, D(x): 0.74, D(G(z)): 0.29\n",
      "Epoch [92/200], Step [600/600], d_loss: 0.8991, g_loss: 1.4224, D(x): 0.76, D(G(z)): 0.32\n",
      "93\n",
      "Epoch [93/200], Step [200/600], d_loss: 1.0053, g_loss: 2.2599, D(x): 0.75, D(G(z)): 0.34\n",
      "Epoch [93/200], Step [400/600], d_loss: 0.6574, g_loss: 1.8900, D(x): 0.81, D(G(z)): 0.26\n",
      "Epoch [93/200], Step [600/600], d_loss: 0.8322, g_loss: 1.4039, D(x): 0.75, D(G(z)): 0.31\n",
      "94\n",
      "Epoch [94/200], Step [200/600], d_loss: 0.8538, g_loss: 1.1222, D(x): 0.82, D(G(z)): 0.35\n",
      "Epoch [94/200], Step [400/600], d_loss: 0.7174, g_loss: 1.8050, D(x): 0.78, D(G(z)): 0.28\n",
      "Epoch [94/200], Step [600/600], d_loss: 0.8090, g_loss: 1.6814, D(x): 0.81, D(G(z)): 0.32\n",
      "95\n",
      "Epoch [95/200], Step [200/600], d_loss: 0.6701, g_loss: 2.2643, D(x): 0.76, D(G(z)): 0.22\n",
      "Epoch [95/200], Step [400/600], d_loss: 0.9740, g_loss: 1.8327, D(x): 0.62, D(G(z)): 0.21\n",
      "Epoch [95/200], Step [600/600], d_loss: 0.7298, g_loss: 1.9486, D(x): 0.76, D(G(z)): 0.24\n",
      "96\n",
      "Epoch [96/200], Step [200/600], d_loss: 0.8015, g_loss: 2.0032, D(x): 0.71, D(G(z)): 0.22\n",
      "Epoch [96/200], Step [400/600], d_loss: 0.9436, g_loss: 1.7906, D(x): 0.77, D(G(z)): 0.38\n",
      "Epoch [96/200], Step [600/600], d_loss: 0.7704, g_loss: 2.1896, D(x): 0.72, D(G(z)): 0.20\n",
      "97\n",
      "Epoch [97/200], Step [200/600], d_loss: 1.0876, g_loss: 1.3930, D(x): 0.64, D(G(z)): 0.27\n",
      "Epoch [97/200], Step [400/600], d_loss: 0.6956, g_loss: 1.7517, D(x): 0.75, D(G(z)): 0.23\n",
      "Epoch [97/200], Step [600/600], d_loss: 0.5750, g_loss: 2.4967, D(x): 0.80, D(G(z)): 0.21\n",
      "98\n",
      "Epoch [98/200], Step [200/600], d_loss: 0.8626, g_loss: 1.4879, D(x): 0.75, D(G(z)): 0.31\n",
      "Epoch [98/200], Step [400/600], d_loss: 0.8020, g_loss: 2.2128, D(x): 0.70, D(G(z)): 0.21\n"
     ]
    }
   ],
   "source": [
    "total_step = len(data_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    print(epoch)\n",
    "    for i, (images, _) in enumerate(data_loader):\n",
    "        \n",
    "        images = images.reshape(batch_size, -1)\n",
    "            \n",
    "        # 创建标签，随后会用于损失函数BCE loss的计算\n",
    "        real_labels = torch.ones(batch_size, 1)  # true_label设为1，表示True\n",
    "        fake_labels = torch.zeros(batch_size, 1) # fake_label设为0，表示False\n",
    "\n",
    "        # ================================================================== #\n",
    "        #                      训练判别模型                      #\n",
    "        # ================================================================== #\n",
    "\n",
    "        # 计算real_损失\n",
    "        # 使用公式 BCE_Loss(x, y): - y * log(D(x)) - (1-y) * log(1 - D(x))，来计算realimage的判别损失\n",
    "        # 其中第二项永远为零，因为real_labels == 1\n",
    "        outputs = D(images)\n",
    "        d_loss_real = criterion(outputs, real_labels)\n",
    "        real_score = outputs\n",
    "        \n",
    "        \n",
    "        # 计算fake损失\n",
    "        # 生成模型根据随机输入生成fake_images\n",
    "        z = torch.randn(batch_size, latent_size)\n",
    "        fake_images = G(z) \n",
    "        # 使用公式 BCE_Loss(x, y): - y * log(D(x)) - (1-y) * log(1 - D(x))，来计算fakeImage的判别损失\n",
    "        # 其中第一项永远为零，因为fake_labels == 0\n",
    "        outputs = D(fake_images)\n",
    "        d_loss_fake = criterion(outputs, fake_labels)\n",
    "        fake_score = outputs\n",
    "        \n",
    "        # 反向传播和优化\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        reset_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        # ================================================================== #\n",
    "        #                       训练生成模型                       #\n",
    "        # ================================================================== #\n",
    "\n",
    "        # 生成模型根据随机输入生成fake_images,然后判别模型进行判别\n",
    "        z = torch.randn(batch_size, latent_size)\n",
    "        fake_images = G(z)\n",
    "        outputs = D(fake_images)\n",
    "        \n",
    "        # 训练生成模型，使之最大化 log(D(G(z)) ，而不是最小化 log(1-D(G(z)))\n",
    "        # 具体的解释在原文第三小节最后一段有解释\n",
    "        # 大致含义就是在训练初期，生成模型G还很菜，判别模型会拒绝高置信度的样本，因为这些样本与训练数据不同。\n",
    "        # 这样log(1-D(G(z)))就近乎饱和，梯度计算得到的值很小，不利于反向传播和训练。\n",
    "        # 换一种思路，通过计算最大化log(D(G(z))，就能够在训练初期提供较大的梯度值，利于快速收敛\n",
    "        g_loss = criterion(outputs, real_labels)\n",
    "        \n",
    "        # 反向传播和优化\n",
    "        reset_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        \n",
    "        if (i+1) % 200 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}, D(x): {:.2f}, D(G(z)): {:.2f}' \n",
    "                  .format(epoch, num_epochs, i+1, total_step, d_loss.item(), g_loss.item(), \n",
    "                          real_score.mean().item(), fake_score.mean().item()))\n",
    "    \n",
    "    # 在第一轮保存训练数据图像\n",
    "    if (epoch+1) == 1:\n",
    "        images = images.reshape(images.size(0), 1, 28, 28)\n",
    "        save_image(denorm(images), os.path.join(sample_dir, 'real_images.png'))\n",
    "    \n",
    "    # 每一轮保存 生成的样本（即fake_images）\n",
    "    fake_images = fake_images.reshape(fake_images.size(0), 1, 28, 28)\n",
    "    save_image(denorm(fake_images), os.path.join(sample_dir, 'fake_images-{}.png'.format(epoch+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 起始阶段\n",
    "fakePath1 = './samples/fake_images-1.png'\n",
    "fakeImg1 = mpimg.imread(fakePath1)\n",
    "\n",
    "fakePath5 = './samples/fake_images-5.png'\n",
    "fakeImg5 = mpimg.imread(fakePath5)\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1 ) # 显示图片\n",
    "plt.imshow(fakeImg1) # 显示图片\n",
    "plt.subplot(1,2,2 ) # 显示图片\n",
    "plt.imshow(fakeImg5) # 显示图片\n",
    "plt.axis('off') # 不显示坐标轴\n",
    "plt.show()\n",
    "\n",
    "fakePath195 = './samples/fake_images-195.png'\n",
    "fakeImg195 = mpimg.imread(fakePath195)\n",
    "\n",
    "fakePath200 = './samples/fake_images-200.png'\n",
    "fakeImg200 = mpimg.imread(fakePath200)\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1 ) # 显示图片\n",
    "plt.imshow(fakeImg195) # 显示图片\n",
    "plt.subplot(1,2,2 ) # 显示图片\n",
    "plt.imshow(fakeImg200) # 显示图片\n",
    "plt.axis('off') # 不显示坐标轴\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
